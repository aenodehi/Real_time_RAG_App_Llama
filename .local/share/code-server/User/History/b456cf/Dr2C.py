import streamlit as st
from streamlit import session_state
import time
import base64
import os
from vectors import EmbeddingsManager
from chatbot import ChatbotManager

def displayPDF(file):
    base64_pdf = base64.b64decode(file.read()).decode('utf-8')

    pdf_display = f'<iframe src="data:application/pdf;base64,{base64_pdf}" width="100%" height="600" type="application/pdf"></iframe>'

    st.markdown(pdf_display, unsafe_allow_html=True)

if 'temp_pdf_path' not in st.session_state:
    st.session_state['temp_pdf_path'] = None

if 'chatbot_manager' not in st.session_state:
    st.session_state['chatbot_manager'] = None

if 'messages' not in st.session_state:
    st.session_state['messages'] = []

st.set_page_config(
    page_title="Document Buddy App",
    layout="wide",
    initial_sidebar_state="expanded",
)

with st.sidebar:
    st.image("logo.png", use_column_width=True)
    st.markdown("### ğŸ“š Your Personal Document Assistant")
    st.markdown("---")

    menu = ["ğŸ  Home", "ğŸ¤– Chatbot", "ğŸ“§ Contact"]
    choice = st.selectbox("Navigate", menu)

if choice == "ğŸ  Home":
    st.title("ğŸ“„ Document Buddy App")
    st.markdown("""
    Welcome to **Document Buddy App**! ğŸš€

    **Built using Open Source Stack (Llama 3.2, BGE Embeddings, and Qdrant running locally within a Docker Container.)**

    - **Upload Documents**: Easily upload your PDF documents.
    - **Summarize**: Get concise summaries of your documents.
    - **Chat**: Interact with your documents through our intelligent chatbot.

    Enhance your document management experience with Document Buddy! ğŸ˜Š
""")
    
elif choice == "ğŸ¤– Chatbot":
    st.title("ğŸ¤– Chatbot Interface (Llama 3.2 RAG ğŸ¦™)")
    st.markdown("---")

    col1, col2, col3 = st.columns(3)

    with col1:
        st.header("ğŸ“‚ Upload Document")
        uploaded_file = st.file_uploader("Upload a PDF", type=["pdf"])
        if uploaded_file is not None:
            st.success("ğŸ“„ File Uploaded Successfully!")
            st.markdown(f"**Filename:** {uploaded_file.name}")
            st.markdown(f"**File Size:** {uploaded_file.size} bytes")

            st.markdown("### ğŸ“– PDF Preview")
            displayPDF(uploaded_file)

            temp_pdf_path = "temp.pdf"
            with open(temp_pdf_path, "wb") as f:
                f.write(uploaded_file.getbuffer())

            st.session_state['temp_pdf_path'] = temp_pdf_path

    with col2:
        st.header("ğŸ§  Embeddings")
        create_embeddings = st.checkbox("âœ… Create Embeddings")
        if create_embeddings:
            if st.session_state['temp_pdf_path'] is None:
                st.warning("âš ï¸ Please upload a PDF first.")
            else:
                try:
                    embedding_manager = EmbeddingManager(
                        model_name="BAAI/bge-small-en",
                        device="cpu",
                        encode_kwargs={"normalized_embeddings": True},
                        qdrant_url="http://localhost:6333",
                        collection_name="vector_db"
                    )

                    with st.spinner("ğŸ”„ Embeddings are in process..."):
                        result = embedding_manager.create_embeddings(st.session_state['temp_pdf_path'])
                        time.sleep(1)
                    st.success(result)

                    if st.session_state['chatbot_manager'] is None:
                        st.session_state['chatbot_manager'] = ChatbotManager(
                            model_name="BAAI/bge-small-en",
                            device="cpu",
                            encode_kwargs={"normalize_embeddings":True},
                            llm_model="llama3.2:3b",
                            llm_temperature=0.7,
                            qdrant_url="http://localhost:6333",
                            collection_name="vector_db"
                        )

                except FileNotFoundError as fnf_error:
                    st.error(fnf_error)
                except ValueError as val_error:
                    st.error(val_error)
                except ConnectionError as conn_error:
                    st.error(conn_error)
                except Exception as e:
                    st.error(f"An unexpected error occurred: {e}")

    with col3:
        st.header("ğŸ’¬ Chat with Document")

        if st.session_state['chatbot_manager'] is None:
            st.info("ğŸ¤– Please upload a PDF and create embeddings to start chatting.")
        else:
            for msg in st.session_state['messages']:
                st.chat_messages(msg['role']).markdown(msg['content'])

            if user_input := st.chat_input("Type your message here..."):
                st.chat_message("user").markdown(user_input)
                st.session_state['messages'].append({"role": "user", "content": user_input})

                with st.spinner("ğŸ¤– Responding..."):
                    try:
                        answer = st.session_state['chatbot_manager'].get_response(user_input)
                        time.sleep(1)
                    except Exception as e:
                        answer = f"âš ï¸ An error occurred while processing your request: {e}"

                st.chat_message("assistant").markdown(answer)
                st.session_state['messages'].append({"role": "assistant", "content": answer})

elif choice == "ğŸ“§ Contact":
    st.title("ğŸ“¬ Contact Us")
    st.markdown("""
    We'd love to hear from you! Whether you have a question, feedback, or want to contribute, feel free to reach out.

    - **Email:** [developer@example.com](mailto:aenodehi@gmail.com) âœ‰ï¸
    - **GitHub:** [Contribute on GitHub](https://github.com/aenodehi) ğŸ› ï¸

    If you'd like to request a feature or report a bug, please open a pull request on our GitHub repository. Your contributions are highly appreciated! ğŸ™Œ
    """)

st.markdown("---")
st.markdown("Â© 2024 Document App by aenodehi. All rights reserved. ğŸ›¡ï¸")
